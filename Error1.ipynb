{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7603"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(111)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  9 16:49:32 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 27%   30C    P0    51W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8     5W / 250W |  10665MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1F:00.0 Off |                  N/A |\n",
      "| 27%   33C    P0    62W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 26%   27C    P0    63W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 27%   30C    P0    64W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:22:00.0 Off |                  N/A |\n",
      "| 29%   28C    P0    57W / 250W |     10MiB / 11019MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:23:00.0 Off |                  N/A |\n",
      "| 22%   30C    P0    55W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:24:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8     1W / 250W |  10665MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    1     22249      C   /usr/bin/python3                           10655MiB |\n",
      "|    7     22393      C   /usr/bin/python3                           10655MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13000, 51, 51)\n",
      "(13000, 51, 51)\n",
      "(13000, 51, 51)\n",
      "(13000, 51, 51)\n",
      "(13000, 51, 51)\n",
      "(13000, 51, 51)\n",
      "(13000, 51, 51)\n",
      "(13000, 51, 51)\n",
      "(13000, 51, 51)\n",
      "(13000, 51, 51)\n"
     ]
    }
   ],
   "source": [
    "train_dir1 = '/mnt/disk2/data/private_data/KRISS/Train/training_data1.mat'\n",
    "train_dir2 = '/mnt/disk2/data/private_data/KRISS/Train/training_data2.mat'\n",
    "train_dir3 = '/mnt/disk2/data/private_data/KRISS/Train/training_data3.mat'\n",
    "train_dir4 = '/mnt/disk2/data/private_data/KRISS/Train/training_data4.mat'\n",
    "train_dir5 = '/mnt/disk2/data/private_data/KRISS/Train/training_data5.mat'\n",
    "train_dir6 = '/mnt/disk2/data/private_data/KRISS/Train/training_data6.mat'\n",
    "train_dir7 = '/mnt/disk2/data/private_data/KRISS/Train/training_data7.mat'\n",
    "train_dir8 = '/mnt/disk2/data/private_data/KRISS/Train/training_data8.mat'\n",
    "train_dir9 = '/mnt/disk2/data/private_data/KRISS/Train/training_data9.mat'\n",
    "train_dir10 = '/mnt/disk2/data/private_data/KRISS/Train/training_data10.mat'\n",
    "\n",
    "train_mat1 = loadmat(train_dir1)\n",
    "train_mat2 = loadmat(train_dir2)\n",
    "train_mat3 = loadmat(train_dir3)\n",
    "train_mat4 = loadmat(train_dir4)\n",
    "train_mat5 = loadmat(train_dir5)\n",
    "train_mat6 = loadmat(train_dir6)\n",
    "train_mat7 = loadmat(train_dir7)\n",
    "train_mat8 = loadmat(train_dir8)\n",
    "train_mat9 = loadmat(train_dir9)\n",
    "train_mat10 = loadmat(train_dir10)\n",
    "\n",
    "train_x_1 = train_mat1['BF0'].transpose(2,0,1)\n",
    "train_x_2 = train_mat2['BF0'].transpose(2,0,1)\n",
    "train_x_3 = train_mat3['BF0'].transpose(2,0,1)\n",
    "train_x_4 = train_mat4['BF0'].transpose(2,0,1)\n",
    "train_x_5 = train_mat5['BF0'].transpose(2,0,1)\n",
    "train_x_6 = train_mat6['BF0'].transpose(2,0,1)\n",
    "train_x_7 = train_mat7['BF0'].transpose(2,0,1)\n",
    "train_x_8 = train_mat8['BF0'].transpose(2,0,1)\n",
    "train_x_9 = train_mat9['BF0'].transpose(2,0,1)\n",
    "train_x_10 = train_mat10['BF0'].transpose(2,0,1)\n",
    "\n",
    "print(train_x_1.shape)\n",
    "print(train_x_2.shape)\n",
    "print(train_x_3.shape)\n",
    "print(train_x_4.shape)\n",
    "print(train_x_5.shape)\n",
    "print(train_x_6.shape)\n",
    "print(train_x_7.shape)\n",
    "print(train_x_8.shape)\n",
    "print(train_x_9.shape)\n",
    "print(train_x_10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130000, 51, 51)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = np.vstack([train_x_1, train_x_2, train_x_3, train_x_4,train_x_5,train_x_6,\n",
    "                    train_x_7,train_x_8,train_x_9,train_x_10])\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117000\n"
     ]
    }
   ],
   "source": [
    "sample = len(train_x) - int(len(train_x)*0.1)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130000, 3)\n"
     ]
    }
   ],
   "source": [
    "## y label, 13000개 만들기\n",
    "\n",
    "temp = []\n",
    "\n",
    "for i in range(1000):\n",
    "    for j in range(13):\n",
    "        temp.append(train_mat1['Y0'][i])\n",
    "for i in range(1000):\n",
    "    for j in range(13):\n",
    "        temp.append(train_mat2['Y0'][i])\n",
    "for i in range(1000):\n",
    "    for j in range(13):\n",
    "        temp.append(train_mat3['Y0'][i])\n",
    "        \n",
    "for i in range(1000):\n",
    "    for j in range(13):\n",
    "        temp.append(train_mat4['Y0'][i])\n",
    "for i in range(1000):\n",
    "    for j in range(13):\n",
    "        temp.append(train_mat5['Y0'][i])\n",
    "for i in range(1000):\n",
    "    for j in range(13):\n",
    "        temp.append(train_mat6['Y0'][i])\n",
    "for i in range(1000):\n",
    "    for j in range(13):\n",
    "        temp.append(train_mat7['Y0'][i])\n",
    "for i in range(1000):\n",
    "    for j in range(13):\n",
    "        temp.append(train_mat8['Y0'][i])\n",
    "for i in range(1000):\n",
    "    for j in range(13):\n",
    "        temp.append(train_mat9['Y0'][i])\n",
    "for i in range(1000):\n",
    "    for j in range(13):\n",
    "        temp.append(train_mat10['Y0'][i])\n",
    "\n",
    "train_y = np.array(temp)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        trainX = train_x[:sample]\n",
    "        trainY = train_y[:sample]\n",
    "        self.trainX = torch.from_numpy(trainX).float() \n",
    "        self.trainY = torch.from_numpy(trainY).float()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.trainX[index]\n",
    "        y = self.trainY[index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        trainX = train_x[sample:]\n",
    "        trainY = train_y[sample:]\n",
    "        self.trainX = torch.from_numpy(trainX).float() \n",
    "        self.trainY = torch.from_numpy(trainY).float()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.trainX[index]\n",
    "        y = self.trainY[index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainDataset()\n",
    "val_data = ValDataset()\n",
    "\n",
    "trainloader = DataLoader(dataset=train_data, batch_size=batch_size, num_workers=0, shuffle=True, drop_last=True)\n",
    "valloader = DataLoader(dataset=val_data, batch_size=len(val_data), num_workers=0, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([32, 51, 51]) torch.Size([32, 3])\n",
      "0\n",
      "torch.Size([13000, 51, 51]) torch.Size([13000, 3])\n"
     ]
    }
   ],
   "source": [
    "for nums, data in enumerate(trainloader):\n",
    "    print(nums)\n",
    "    x,y = data\n",
    "    print(x.size(),y.size())\n",
    "    if nums == 0:\n",
    "        break\n",
    "        \n",
    "for nums, data in enumerate(valloader):\n",
    "    print(nums)\n",
    "    x,y = data\n",
    "    print(x.size(),y.size())\n",
    "    if nums == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGNet, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "\n",
    "        # (51,51)\n",
    "        torch.nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        torch.nn.BatchNorm2d(64),    \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        torch.nn.BatchNorm2d(64),    \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=2, stride=2), # (25,25)\n",
    "\n",
    "        torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        torch.nn.BatchNorm2d(128),    \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        torch.nn.BatchNorm2d(128),    \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=2, stride=2), # (12,12)\n",
    "\n",
    "        torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        torch.nn.BatchNorm2d(256),    \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        torch.nn.BatchNorm2d(256),    \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=2, stride=2), # (6,6)\n",
    "            \n",
    "        torch.nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        torch.nn.BatchNorm2d(512),    \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        torch.nn.BatchNorm2d(512),    \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "        )\n",
    "        # (batch, 128,6,6)\n",
    "        self.linear = nn.Sequential(\n",
    "        torch.nn.Linear(512*3*3, 2048),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(2048, 1024),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(1024, 512),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(512, 256),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(256,3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = self.linear(out.view(-1, 128*6*6))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGNet(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU()\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): ReLU()\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU()\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=4608, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_model = VGGNet().to(device)\n",
    "print(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  9 16:49:47 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8    13W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8     5W / 250W |  10665MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1F:00.0 Off |                  N/A |\n",
      "| 27%   33C    P2    61W / 250W |    947MiB / 11019MiB |      3%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8    20W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 27%   30C    P8    25W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:22:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8     6W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:23:00.0 Off |                  N/A |\n",
      "| 27%   30C    P8    18W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:24:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8     1W / 250W |  10665MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    1     22249      C   /usr/bin/python3                           10655MiB |\n",
      "|    2     23908      C   /usr/bin/python3                             937MiB |\n",
      "|    7     22393      C   /usr/bin/python3                           10655MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16882371"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in train_model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(model):\n",
    "    for p in model.parameters():\n",
    "        if(p.dim() > 1):\n",
    "            nn.init.xavier_normal_(p)\n",
    "init_params(train_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3656\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(trainloader)\n",
    "print(total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.MSELoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(train_model.parameters(), lr=0.00001, weight_decay=0.000002)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-26bfba0be667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mval_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-bb753ddbc960>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m         )\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input."
     ]
    }
   ],
   "source": [
    "train_model.train()\n",
    "train_iter_losses = []\n",
    "train_epoch_losses = []\n",
    "\n",
    "valid_losses = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in trainloader:\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = train_model(X.unsqueeze(1))\n",
    "        loss = criterion(output, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_iter_losses.append(loss)\n",
    "        avg_cost += loss / total_batch\n",
    "        \n",
    "    train_epoch_losses.append(avg_cost)    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        train_model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        for x, y in valloader:\n",
    "            val_x = x.to(device)\n",
    "            val_y = y.to(device)\n",
    "            \n",
    "            val_output = train_model(val_x.unsqueeze(1))\n",
    "            v_loss = criterion(val_output, val_y)\n",
    "            \n",
    "            val_loss += v_loss \n",
    "        valid_losses.append(val_loss)\n",
    "        \n",
    "#         if early_stopping.validate(val_loss):\n",
    "#             break\n",
    "\n",
    "    if epoch % 1 == 0:    \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'Train Loss =''{:.4f}'.format(avg_cost), 'Val Loss=''{:.4f}'.format(val_loss))\n",
    "\n",
    "\n",
    "print('Learning finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  9 16:49:14 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    13W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8     5W / 250W |  10665MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1F:00.0 Off |                  N/A |\n",
      "| 29%   32C    P8    21W / 250W |   9905MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8    20W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8    24W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:22:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8     5W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:23:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8    17W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:24:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8     1W / 250W |  10665MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    1     22249      C   /usr/bin/python3                           10655MiB |\n",
      "|    2     23697      C   /usr/bin/python3                            9895MiB |\n",
      "|    7     22393      C   /usr/bin/python3                           10655MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
