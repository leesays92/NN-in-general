{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"girk\"><출처></span>\n",
    "\n",
    "- https://medium.com/daangn/pytorch-multi-gpu-%ED%95%99%EC%8A%B5-%EC%A0%9C%EB%8C%80%EB%A1%9C-%ED%95%98%EA%B8%B0-27270617936b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# model = Model()\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multi GPU \n",
    "\n",
    "![image](https://user-images.githubusercontent.com/48466625/63988848-0cbf5f00-cb19-11e9-821a-2d535cf92a07.png)\n",
    "\n",
    "- PyTorch에서는 기본적으로 multi-gpu 학습을 위한 ```Data Parallel``` 기능을 제공\n",
    "- 우선 model을 각 GPU에 복사해서 할당해야 하고, iteration마다 batch를 GPU 갯수만큼 나눈다.(이 과정을 __scatter__)\n",
    "- 이렇게 입력을 나누고나면, 각 GPU에서 forward 과정이 진행되고,\n",
    "- 각 입력에 대해 모델이 출력을 내보내면 이제 이 출력들을 하나의 GPU로 모은다.(__gather__)\n",
    "- Back propagation은 각 GPU에서 수행해서, 각 GPU에 있던 모델의 gradient를 구하고, 또 하나의 GPU로 모아서 업데이트 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#### nn.DataParallel로 model을 감싸주면, \n",
    "# 위 언급한대로 replicate -> scatter -> parallel_apply -> gather 순서대로 진행함\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "#### RNN 계열 사용할떄는\n",
    "### nn.DataPArallel(model, dim=1).to(device) 해야 잘된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">__number of workers : recommended to set (4*num_GPUs)__</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 메모리 불균형 문제 해결?\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/48466625/63991361-68dab100-cb22-11e9-8007-f4055bc07758.png)\n",
    "\n",
    "- 0번이 다른 GPU에 비해 6기가정도 더 많은 메모리를 사용하고 있음. \n",
    "  - 이렇게 하나의 GPU가 상대적으로 많은 메모리를 사용하면, batch size를 많이 키울 수 없다.\n",
    "  - <span class=\"mark\">메모리 사용의 불균형을 해결해야함.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT(args)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.cuda()\n",
    "\n",
    "...\n",
    "\n",
    "for i, (inputs, labels) in enumerate(trainloader):\n",
    "    outputs = model(inputs)          \n",
    "    loss = criterion(outputs, labels)     \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()                        \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 메모리 불균형을 간단히 해결하는 방법은, 출력을 다른 GPU로 모으는 것.\n",
    "  - Default로 설정된 GPU의 경우 gradient 또한 이 GPU로 모이기에 메모리 사용량이 상당히 많음\n",
    "- 간단히 출력을 모으고 싶은 GPU 번호 ```output_device``` 를 설정하면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2, 3'\n",
    "model = nn.DataParallel(model, output_device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/48466625/63991478-06ce7b80-cb23-11e9-8cd0-6668fb650661.png)\n",
    "\n",
    "- <span class=\"mark\">그러나, 이는 적절한 해결방법이 아님.</span>\n",
    "  - 1번 메모리가 늘었지만, 여전히 균형이 잡히지 않았으며,\n",
    "  - batchsize가 늘어나면 이대로 메모리 사용량이 늘어날 것. \n",
    "  - GPU-util을 보면 GPU를 제대로 활용하지 못하는 것을 확인함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Custom으로 DataParallel 사용하기\n",
    "\n",
    "- DataParallel을 사용하면서 메모리 불균형 문제를 해결할 수 있는 방법에 대한 힌트\n",
    "- GPU 메모리가 늘어나는 것은 <span class=\"mark\">모델의 출력을 하나의 GPU로 모은 것이기 때문</span>이며,\n",
    "- 왜 하나의 GPU로 출력을 모으냐면, <span class=\"mark\">모델의 출력을 사용해서 loss function을 계산</span>해야하기 때문.\n",
    "  - 모델은 DataParallel로 병렬로 연산을 하게 했지만,\n",
    "  - loss function이 그대로이기 떄문에 하나의 GPU에서 loss를 계산함.\n",
    "  - <span class=\"mark\">loss function도 Parallel하게 만들어서, 병렬로 연산하도록 만든다면~!</span>\n",
    "  \n",
    "![image](https://user-images.githubusercontent.com/48466625/63991721-daffc580-cb23-11e9-9781-dcef6f960b99.png)\n",
    "\n",
    "- ```DataParallelCriterion```을 사용할 경우 일반적인 DataParallel 모델로 감싸면 안됨.\n",
    "  - DataParallel은 기본적으로 하나의 GPU로 출력을 모으기 떄문,\n",
    "- <span class=\"mark\">DataParallelModel과 DataParallelCriterion을 사용하자.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from parallel import DataParallelModel, DataParallelCriterion\n",
    "\n",
    "model = BERT(args)\n",
    "model = DataParallelModel(model)\n",
    "model.cuda()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "criterion = DataParallelCriterion(criterion) \n",
    "\n",
    "...\n",
    "\n",
    "for i, (inputs, labels) in enumerate(trainloader):\n",
    "    outputs = model(inputs)          \n",
    "    loss = criterion(outputs, labels)     \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()                        \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/48466625/63991842-42b61080-cb24-11e9-971e-2cbe5ab10753.png)\n",
    "\n",
    "- DataParallel만 사용할 때보다, 1번과 2번 GPU의 메모리 차이가 상당히 줄었음.\n",
    "- <span class=\"mark\">하지만, GPU-Util을 보면 여전히 제대로 활용을 못하고 있음.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Distributed 패키지 사용\n",
    "\n",
    "- 분산학습은 여러 컴퓨터(머신)를 사용해서 학습되기 위한 것이지만, \n",
    "- <span class=\"mark\">분산학습을 통해 하나의 머신에서 여러 GPU로 학습도 가능함.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    args.world_size = ngpus_per_node * args.world_size\n",
    "    mp.spawn(main_worker, nprocs=ngpus_per_node, \n",
    "             args=(ngpus_per_node, args))\n",
    "    \n",
    "    \n",
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    global best_acc1\n",
    "    args.gpu = gpu\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    \n",
    "    print(\"Use GPU: {} for training\".format(args.gpu))\n",
    "    args.rank = args.rank * ngpus_per_node + gpu\n",
    "    \n",
    "    # 각 GPU 마다 분산 학습을 위한 초기화를 실행\n",
    "    # multi-GPU의 경우 backend로 'nccl'을 사용\n",
    "    # init_method에서는 FREEPORT에 사용 가능한 port를 적으면 됨\n",
    "    dist.init_process_group(backend='nccl', \n",
    "                            init_method='tcp://127.0.0.1:FREEPORT',\n",
    "                            world_size=args.world_size, \n",
    "                            rank=args.rank)\n",
    "    \n",
    "    model = Bert()\n",
    "    model.cuda(args.gpu)\n",
    "    \n",
    "    # DataParallel 대신에 DistributedDataParallel을 사용\n",
    "    model = DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(args.num_epochs):\n",
    "        model = train(model)\n",
    "        acc = test(model, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataLoader가 각 인풋을 프로세스에 전달하기 위해서, <span class=\"mark\">```DistriubtedSampler```를 사용함</span>\n",
    "  - 이는 ```DistributedDataParallel```과 함께 사용해야 함.\n",
    "- 사용 방법은 dataset을 DistributedSampler로 감싸주고, DataLoader에서 이를 sampler 인자에 넣어줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "train_dataset = datasets.ImageFolder(traindir, ...)\n",
    "train_sampler = DistributedSampler(train_dataset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/48466625/63993452-83fdee80-cb2b-11e9-8e64-45a06bd5d414.png)\n",
    "\n",
    "- 메모리 사용량이 완전 동일하고, GPU-util 수치도 상당히 높다.\n",
    "- 하지만, <span class=\"mark\">분산학습시에 간간히 문제가 발생할 수 있음.</span>\n",
    "  - 학습에 사용하지 않는 파라미터가 있을 경우 문제를 일으킨다 등등..\n",
    "- 신경 안쓰고 학습하려면?\n",
    "  - <span class=\"mark\">Nvidia의 Apex 패키지?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Nvidia Apex 패키지\n",
    "\n",
    "- Nvidia Apex 패키지, mixed precision 연산을 위한 패키지.\n",
    "  - 보통 32비트 연산을 하는 딥러닝을 <span class=\"mark\">16비트 연산을 사용해 메모리를 절약하고 속도를 높이겠다는 것.</span>\n",
    "  - Distributed 관련 기능이 포함됨.\n",
    "  - apex에서 ```DistributedDataParallel```을 임포트해서 사용함.\n",
    "  - 따로 멀티 프로세싱을 진행하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "\n",
    "def main():\n",
    "    global args\n",
    "    \n",
    "    args.gpu = 0\n",
    "    args.world_size = 1\n",
    "    \n",
    "    args.gpu = args.local_rank\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    torch.distributed.init_process_group(backend='nccl',\n",
    "                                         init_method='env://')\n",
    "    args.world_size = torch.distributed.get_world_size()\n",
    "    \n",
    "    model = Bert()\n",
    "    model.cuda(args.gpu)\n",
    "    \n",
    "    # 모델을 DDP로 감싸줌\n",
    "    model = DDP(model, delay_allreduce=True)\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(args.num_epochs):\n",
    "        model = train(model)\n",
    "        acc = test(model, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실행 방법\n",
    "\n",
    "python -m torch.distributed.launch --nproc_per_node=4 main.py \\\n",
    "    --batch_size 60 \\\n",
    "    --num_workers 2 \\\n",
    "    --gpu_devices 0 1 2 3\\\n",
    "    --distributed \\\n",
    "    --log_freq 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/48466625/63993838-439f7000-cb2d-11e9-9363-78d6ceed29ae.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 학습법 선택하기\n",
    "\n",
    "- DataParallel -> 불균형 문제\n",
    "- Custom DataParallel -> 불균형은 해결하지만 GPU-util 문제\n",
    "- Distriubted DataParallel -> 불균형, GPU-util 해결하지만, 간간히 문제\n",
    "- Nvidia Apex\n",
    "\n",
    "그러나,항상 Apex가 좋은 것은 아님.\n",
    "\n",
    "- 가령, 이미지 분류 학습시에는 DataParallel만으로도 충분함.\n",
    "  - GPU 메모리 불균형 문제는 BERT 같은 알고리즘이 출력히 상당히 크기 때문."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tutorials\n",
    "\n",
    "- model = nn.DataParallel(model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T05:19:14.031614Z",
     "start_time": "2019-08-30T05:19:14.027623Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    " \n",
    "# Parameters and DataLoaders\n",
    "input_size = 5\n",
    "output_size = 2\n",
    " \n",
    "batch_size = 30\n",
    "data_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T05:21:43.966115Z",
     "start_time": "2019-08-30T05:21:43.961136Z"
    }
   },
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "random_loader = DataLoader(dataset=RandomDataset(input_size, 100), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T05:24:06.460146Z",
     "start_time": "2019-08-30T05:24:06.456158Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.fc(input)\n",
    "        print(\"Our model: input_size\", input.size(), \"output_size\", output.size())\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. DataParallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 8 GPUs!\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_size, output_size)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, device_ids=[0,2])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Run the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: input_size torch.Size([15, 5]) output_size torch.Size([15, 2])\n",
      "Our model: input_size torch.Size([15, 5]) output_size torch.Size([15, 2])\n",
      "Outside: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "Our model: input_size torch.Size([15, 5]) output_size torch.Size([15, 2])\n",
      "Our model: input_size torch.Size([15, 5]) output_size torch.Size([15, 2])\n",
      "Outside: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "Our model: input_size torch.Size([15, 5]) output_size torch.Size([15, 2])\n",
      "Our model: input_size torch.Size([15, 5]) output_size torch.Size([15, 2])\n",
      "Outside: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "Our model: input_size torch.Size([5, 5]) output_size torch.Size([5, 2])\n",
      "Our model: input_size torch.Size([5, 5]) output_size torch.Size([5, 2])\n",
      "Outside: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "for data in random_loader:\n",
    "    if torch.cuda.is_available():\n",
    "        input_var = Variable(data.cuda())\n",
    "    else:\n",
    "        input_var = Variable(data)\n",
    "    \n",
    "    output = model(input_var)\n",
    "    print(\"Outside: input size\", input_var.size(), \"output size\", output.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
